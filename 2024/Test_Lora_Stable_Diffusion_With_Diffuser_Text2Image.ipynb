{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpjWonC5MwDE"
      },
      "source": [
        "# Test Lora Stable Diffusion With Diffuser Text2Image\n",
        "\n",
        "## Note :\n",
        "This notebook is used for data scientific research purpose, any misuse will make community ML learner losing free gpu access. the industrial hardware resource will can't cope up with unintended newbie no coder demand please refrain yourself if system down sign or monetization of mass traffic greedy policy starting show up.\n",
        "\n",
        "please be wary in technological administration greedy and politics.\n",
        "\n",
        "and if you have more cash, feed them to get them on the path of charitable institutions.\n",
        "\n",
        "this is what i called counter politics to make more opensource prefered and free service increase it available or availability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSxdLsTAJWWJ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch huggingface_hub pyexiv2 peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVonEI-5Ains"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/diffusers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install diffusers"
      ],
      "metadata": {
        "id": "BfhW_5mx1aZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP-8d0vxJ5u4"
      },
      "outputs": [],
      "source": [
        "from diffusers import(\n",
        "    StableDiffusionPipeline,\n",
        "    DPMSolverMultistepScheduler,\n",
        "    AutoencoderKL,\n",
        ")\n",
        "import transformers\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from huggingface_hub import hf_hub_download,login\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_949C8HAinu"
      },
      "source": [
        "For Private Huggingface Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bRx0cbwAinw"
      },
      "outputs": [],
      "source": [
        "# def read_specific_line(file_path, line_number):\n",
        "#     try:\n",
        "#         with open(file_path, 'r') as file:\n",
        "#             for current_line_number, line in enumerate(file, start=1):\n",
        "#                 if current_line_number == line_number:\n",
        "#                     return line.strip()\n",
        "#         return f\"Line {line_number} not found in the file.\"\n",
        "#     except FileNotFoundError:\n",
        "#         return \"File not found.\"\n",
        "#     except Exception as e:\n",
        "#         return f\"An error occurred: {e}\"\n",
        "\n",
        "# # Example usage\n",
        "# file_path = \"./hf_token.txt\"\n",
        "# line_number = int(input(\"Enter the line number you want to read: \"))\n",
        "# specific_line = read_specific_line(file_path, line_number)\n",
        "# print(f\"Line {line_number}: {specific_line}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZSx9TcHKB5f"
      },
      "outputs": [],
      "source": [
        "# login(token=str(specific_line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wPXM9GOE1dx"
      },
      "outputs": [],
      "source": [
        "login(token=\"your_token\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4Ve1zD6JvN4"
      },
      "source": [
        "Model Download Civit Ai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6jj__iQAiny"
      },
      "source": [
        "Pruned MeinaMixV11 FP16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9UBSyzMLxtI"
      },
      "outputs": [],
      "source": [
        "# !wget --content-disposition -O model.safetensors  https://civitai.com/api/download/models/119057"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnRamCUuAinz"
      },
      "source": [
        "AingDiffusion V8 Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4cKN1-oAinz"
      },
      "outputs": [],
      "source": [
        "checkpoint_repo = \"faizalnf1800/AingDiffusion-V8-FP16-SD1.5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPMOM_0ituPW"
      },
      "outputs": [],
      "source": [
        "checkpoint_repo = \"faizalnf1800/AingDiffusion-V8-FP16-SD1.5-BaseClip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_repo = \"faizalnf1800/AingDiffusion-V8-FP16-SD1.5-Blessed2Vae\""
      ],
      "metadata": {
        "id": "RC9Nv9QgzyYH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SErMqa6kMwW6"
      },
      "source": [
        "Lora Download HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOKN37XOM00q"
      },
      "outputs": [],
      "source": [
        "lora_repo = \"finnstrom3693/anime-character-lora-mp-fp16\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHwMNsDmAin1"
      },
      "source": [
        "Lora Download From Other Source as File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjrnRZm9BBWd"
      },
      "outputs": [],
      "source": [
        "# lora_path = \"/content\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-KvZt-pMnQ7"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZrY_0UwAin2"
      },
      "outputs": [],
      "source": [
        "# model = \"/content/model.safetensors\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4o7-YlpzMph-"
      },
      "outputs": [],
      "source": [
        "precision = 'half' # @param [\"half\", \"full\" ,\"bf16\"]\n",
        "if precision == \"half\":\n",
        "    selected_precision = torch.float16\n",
        "elif precision == \"full\":\n",
        "    selected_precision = torch.float32\n",
        "elif precision == \"bf16\":\n",
        "    selected_precision = torch.bfloat16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ROygRtOAin3"
      },
      "source": [
        "Load Model From File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ldiFmCvOva-"
      },
      "outputs": [],
      "source": [
        "# pipe = StableDiffusionPipeline.from_single_file(model,\n",
        "#                                             torch_dtype=selected_precision,\n",
        "#                                             use_safetensors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DzBwax0Ain4"
      },
      "source": [
        "Load Model From Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz--mSagAin4"
      },
      "outputs": [],
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(checkpoint_repo,\n",
        "                                            torch_dtype=selected_precision,\n",
        "                                            use_safetensors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6Clco8esWpCl"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1UAEVl9SPXXb"
      },
      "outputs": [],
      "source": [
        "pipe.to(device)\n",
        "pipe.safety_checker = None\n",
        "pipe.requires_safety_checker = False\n",
        "DPMSolverMultistepScheduler\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(\n",
        "    pipe.scheduler.config,\n",
        "    algorithm_type=\"sde-dpmsolver++\",\n",
        "    use_karras_sigmas=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjDGTXx7Pj-f"
      },
      "source": [
        "Load Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiq4gZzJPcyW"
      },
      "outputs": [],
      "source": [
        "pipe.load_lora_weights(lora_repo,weight_name=\"pytorch_lora_weights.safetensors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9Dbgtd5Ain6"
      },
      "outputs": [],
      "source": [
        "#pipe.load_lora_weights(lora_path,weight_name=\"pytorch_lora_weights.safetensors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt-pjd8UO3uj"
      },
      "outputs": [],
      "source": [
        "lora_scale=0.8 # @param [\"1\",\"0.8\",\"1.2\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsCu4YPEPoAY"
      },
      "outputs": [],
      "source": [
        "pipe.fuse_lora(lora_scale=lora_scale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Nz_cBMTWV_"
      },
      "source": [
        "Unload Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj1wiiocTYl4"
      },
      "outputs": [],
      "source": [
        "# pipe.unload_lora_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKKezBwoTcv6"
      },
      "source": [
        "Reset Lora Strength"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd6X-qMhTktX"
      },
      "outputs": [],
      "source": [
        "# pipe.unfuse_lora()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IL3tGzZP_jp"
      },
      "source": [
        "Inference Text to Image Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "R05DYvpIP4I4"
      },
      "outputs": [],
      "source": [
        "# @title Inference Settings\n",
        "\n",
        "prompt = \"1boy,prince,blonde hair,red military clothes,light armor,handsome,chest to head upperbody shot,cloud,high quality,masterpiece,crimson sky background\" # @param {type:\"string\"}\n",
        "negative_prompt = \"lowres,text,error,cropped,worst quality,low quality,jpeg artifacts,ugly,duplicate,morbid,mutilated,out of frame,extra fingers,mutated hands,poorly drawn hands,poorly drawn face,mutation,deformed,blurry,dehydrated,bad anatomy,bad proportions,extra limbs,cloned face,disfigured,gross proportions,malformed limbs,missing arms,missing legs,extra arms,extra legs,fused fingers,too many fingers,long neck,username,watermark,signature\" # @param {type:\"string\"}\n",
        "orientation = 'square' # @param [\"portrait\", \"square\", \"landscape\"]\n",
        "# Set width and height based on orientation\n",
        "if orientation == 'portrait':\n",
        "    width = 512 # Example width for portrait\n",
        "    height = 768 # Example height for portrait\n",
        "elif orientation == 'square':\n",
        "    width = 512 # Example width for square\n",
        "    height = 512 # Example height for square\n",
        "elif orientation == 'landscape':\n",
        "    width = 768 # Example width for landscape\n",
        "    height = 512 # Example height for landscape\n",
        "size=str(width)+\"x\"+str(height)\n",
        "cfg_scale = 7 # @param {type:\"integer\"}\n",
        "steps = 20 # @param {type:\"integer\"}\n",
        "sampler = \"DPM++ SDE Karras\" # @param {type:\"string\"}\n",
        "modelname = \"faizalnf1800/AingDiffusion-V8-FP16-SD1.5-Blessed2Vae\" # @param {type:\"string\"}\n",
        "loraname = \"AnimeCharacter\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4reAYABHSKxh"
      },
      "source": [
        "Random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i5qyzN1SJHC"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "\n",
        "# manual_seed = random.randint(1,999999)\n",
        "# print(\"seed :\",manual_seed)\n",
        "# generator = torch.Generator(device=\"cuda\").manual_seed(manual_seed)\n",
        "# images = pipe(\n",
        "#             prompt = prompt,\n",
        "#             negative_prompt = negative_prompt,\n",
        "#             width = width,\n",
        "#             height = height,\n",
        "#             guidance_scale = cfg_scale,\n",
        "#             num_inference_steps = steps,\n",
        "#             num_images_per_prompt = 4,\n",
        "#             generator = generator\n",
        "#         ).images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLkmVhR-SMMu"
      },
      "source": [
        "Fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-12Di8lSNZb"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "manual_seed = 3245\n",
        "print(\"seed :\",manual_seed)\n",
        "generator = torch.Generator(device=device).manual_seed(manual_seed)\n",
        "images = pipe(\n",
        "            prompt = prompt,\n",
        "            negative_prompt = negative_prompt,\n",
        "            width = width,\n",
        "            height = height,\n",
        "            guidance_scale = cfg_scale,\n",
        "            num_inference_steps = steps,\n",
        "            num_images_per_prompt = 4,\n",
        "            generator = generator\n",
        "        ).images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFbSkystShN4"
      },
      "source": [
        "Show Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqYDW_0HSgR2"
      },
      "outputs": [],
      "source": [
        "def plot_images(images):\n",
        "    N = len(images)\n",
        "    n_cols = 2\n",
        "    n_rows = int(np.ceil(N / n_cols))\n",
        "\n",
        "    plt.figure(figsize = (20, 5 * n_rows))\n",
        "    for i in range(len(images)):\n",
        "        plt.subplot(n_rows, n_cols, i + 1)\n",
        "        plt.title(i)\n",
        "        plt.imshow(np.array(images[i]))\n",
        "        plt.axis(False)\n",
        "    plt.show()\n",
        "plot_images(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGyKatjISwu6"
      },
      "source": [
        "Save and Write Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gSkPfxbGAin-"
      },
      "outputs": [],
      "source": [
        "use_lora = \"False\" # @param [\"True\",\"False\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aEUGd7B8SXDR"
      },
      "outputs": [],
      "source": [
        "import pyexiv2\n",
        "import json\n",
        "import os\n",
        "\n",
        "def get_unique_filename(base_name, ext):\n",
        "    \"\"\"Generate a unique filename by appending a numeric suffix if necessary.\"\"\"\n",
        "    counter = 1\n",
        "    unique_name = f\"{base_name}{ext}\"\n",
        "    while os.path.exists(unique_name):\n",
        "        unique_name = f\"{base_name}_{counter}{ext}\"\n",
        "        counter += 1\n",
        "    return unique_name\n",
        "\n",
        "for i in range(len(images)):\n",
        "    # Save image with unique filename\n",
        "    base_filename = f\"image{i}\"\n",
        "    ext = \".png\"\n",
        "    unique_filename = get_unique_filename(base_filename, ext)\n",
        "    images[i].save(unique_filename)\n",
        "\n",
        "    metadata_diffusers = {\n",
        "        \"prompt\": prompt,\n",
        "        \"negativePrompt\": negative_prompt,\n",
        "        \"steps\": steps,\n",
        "        \"samplerName\": sampler,\n",
        "        \"cfgScale\": cfg_scale,\n",
        "        \"seed\": manual_seed,\n",
        "        \"clipskip\": 1,\n",
        "        \"baseModel\": \"SD 1.5\",\n",
        "        \"checkpointModel\": modelname,\n",
        "        \"seed\": manual_seed\n",
        "    }\n",
        "\n",
        "    if use_lora == True:\n",
        "        metadata_diffusers.update({\n",
        "            \"loraScale\": lora_scale,\n",
        "            \"loraModel\": loraname\n",
        "        })\n",
        "\n",
        "    new_metadata = {\n",
        "        \"Exif.Photo.UserComment\": metadata_diffusers\n",
        "    }\n",
        "\n",
        "    img = pyexiv2.Image(unique_filename)\n",
        "    img.modify_exif(new_metadata)\n",
        "\n",
        "# Save metadata to a text file with a unique name\n",
        "metadata_filename_base = \"metadata\"\n",
        "metadata_filename_ext = \".txt\"\n",
        "unique_metadata_filename = get_unique_filename(metadata_filename_base, metadata_filename_ext)\n",
        "with open(unique_metadata_filename, 'w') as f:\n",
        "    f.write(json.dumps(metadata_diffusers, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3Cf9_kGNsCp"
      },
      "source": [
        "Clean GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvSboC9vN0fX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "# Delete any references to tensors stored in GPU\n",
        "del pipe\n",
        "del generator\n",
        "# Add any other variables you have here\n",
        "\n",
        "# Collect garbage to free up memory\n",
        "gc.collect()\n",
        "\n",
        "# Empty the CUDA cache\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkWQvFI8Q9z1"
      },
      "source": [
        "Zip Generated File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nyAb9YUiRCji"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zip_txt_and_png(directory, zip_name):\n",
        "    # Create a ZipFile object\n",
        "    with zipfile.ZipFile(zip_name, 'w') as zipf:\n",
        "        # Walk through the directory\n",
        "        for root, dirs, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                # Check if the file is a .txt or .png\n",
        "                if file.endswith('.txt') or file.endswith('.png'):\n",
        "                    # Create the full filepath by joining the root and file name\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    # Add the file to the zip file\n",
        "                    zipf.write(file_path, os.path.relpath(file_path, directory))\n",
        "\n",
        "# Usage example\n",
        "directory_to_zip = os.getcwd()\n",
        "output_zip_file = 'research_test_image.zip'\n",
        "zip_txt_and_png(directory_to_zip, output_zip_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuCQLfvgS-C0"
      },
      "source": [
        "Check Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EPONtX_TKPu"
      },
      "outputs": [],
      "source": [
        "# img = pyexiv2.Image(r'image0.png')\n",
        "# data = img.read_exif()\n",
        "# print(data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}