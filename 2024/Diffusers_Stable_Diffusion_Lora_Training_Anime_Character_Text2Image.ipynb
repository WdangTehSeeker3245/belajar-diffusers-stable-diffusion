{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmzYyS9FMPVU"
      },
      "source": [
        "Pinned Documentary URL <br>\n",
        "* [Diffusers Github](https://github.com/huggingface/diffusers)\n",
        "* [Diffusers HF](https://huggingface.co/docs/diffusers/index)\n",
        "* [WdangTehSeeker3245 Github](https://github.com/WdangTehSeeker3245/belajar-diffusers-stable-diffusion)\n",
        "* [Precision Info](https://moocaholic.medium.com/fp64-fp32-fp16-bfloat16-tf32-and-other-members-of-the-zoo-a1ca7897d407)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AhNsHuVOSBu"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1EP76c6OxLV"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/huggingface/diffusers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyzbZv6rO2VI"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/diffusers/examples/text_to_image/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4eFEf6I0P5Pc"
      },
      "outputs": [],
      "source": [
        "!cp /content/diffusers/examples/text_to_image/train_text_to_image_lora.py /content/train_text_to_image_lora.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install xformers"
      ],
      "metadata": {
        "id": "pmZlExx2CNR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install bitsandbytes"
      ],
      "metadata": {
        "id": "uaJev3glGpdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note :    \n",
        "Fix error in push to hub without validation image"
      ],
      "metadata": {
        "id": "jwxT5bZgah12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def modify_code(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Define the regex pattern to find the specific code block to replace\n",
        "    pattern = re.compile(\n",
        "        r\"( *)(if args\\.push_to_hub:\\s+)\"\n",
        "        r\"(\\s*save_model_card\\(\\s*\"\n",
        "        r\"repo_id,\\s*\"\n",
        "        r\"images=images,\\s*\"\n",
        "        r\"base_model=args\\.pretrained_model_name_or_path,\\s*\"\n",
        "        r\"dataset_name=args\\.dataset_name,\\s*\"\n",
        "        r\"repo_folder=args\\.output_dir,\\s*\"\n",
        "        r\"\\)\\s*)\"\n",
        "    )\n",
        "\n",
        "    # Define the regex pattern to find and delete the previous upload_folder block\n",
        "    upload_pattern = re.compile(\n",
        "        r\"( *)(upload_folder\\(\\s*\"\n",
        "        r\"repo_id=repo_id,\\s*\"\n",
        "        r\"folder_path=args\\.output_dir,\\s*\"\n",
        "        r\"commit_message=\\\"End of training\\\",\\s*\"\n",
        "        r\"ignore_patterns=\\[\\\"step_\\*\\\", \\\"epoch_\\*\\\"\\],\\s*\"\n",
        "        r\"\\)\\s*)\"\n",
        "        r\"\"\"(\\s*accelerator\\.end_training\\(\\)\\s*)\"\"\"\n",
        "    )\n",
        "\n",
        "    # Define a function to construct the replacement block with the same indentation\n",
        "    def replacement(match):\n",
        "        indent = match.group(1)\n",
        "        return (\n",
        "            f\"{indent}if args.push_to_hub:\\n\"\n",
        "            f\"{indent}    if args.validation_prompt is not None:\\n\"\n",
        "            f\"{indent}        save_model_card(\\n\"\n",
        "            f\"{indent}            repo_id,\\n\"\n",
        "            f\"{indent}            images=images,\\n\"\n",
        "            f\"{indent}            base_model=args.pretrained_model_name_or_path,\\n\"\n",
        "            f\"{indent}            dataset_name=args.dataset_name,\\n\"\n",
        "            f\"{indent}            repo_folder=args.output_dir,\\n\"\n",
        "            f\"{indent}        )\\n\"\n",
        "            f\"{indent}    else:\\n\"\n",
        "            f\"{indent}        save_model_card(\\n\"\n",
        "            f\"{indent}            repo_id,\\n\"\n",
        "            f\"{indent}            base_model=args.pretrained_model_name_or_path,\\n\"\n",
        "            f\"{indent}            dataset_name=args.dataset_name,\\n\"\n",
        "            f\"{indent}            repo_folder=args.output_dir,\\n\"\n",
        "            f\"{indent}        )\\n\"\n",
        "            f\"{indent}    upload_folder(\\n\"\n",
        "            f\"{indent}        repo_id=repo_id,\\n\"\n",
        "            f\"{indent}        folder_path=args.output_dir,\\n\"\n",
        "            f\"{indent}        commit_message=\\\"End of training\\\",\\n\"\n",
        "            f\"{indent}        ignore_patterns=[\\\"step_*\\\", \\\"epoch_*\\\"],\\n\"\n",
        "            f\"{indent}    )\\n\"\n",
        "            f\"    accelerator.end_training()\\n\\n\"\n",
        "        )\n",
        "\n",
        "    # Remove the previous upload_folder block\n",
        "    content = upload_pattern.sub(\"\", content)\n",
        "\n",
        "    # Replace the save_model_card block and add the upload_folder block\n",
        "    new_content = pattern.sub(replacement, content)\n",
        "\n",
        "    # Write the modified content back to the file\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(new_content)\n",
        "\n",
        "# Usage example\n",
        "file_path = 'train_text_to_image_lora.py'\n",
        "modify_code(file_path)\n",
        "print(\"edit py success\")"
      ],
      "metadata": {
        "id": "Ni49xxz6i4K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdBigTuj08Uk"
      },
      "outputs": [],
      "source": [
        "!accelerate config default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j4AgODSQOVSH"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download,login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def read_specific_line(file_path, line_number):\n",
        "#     try:\n",
        "#         with open(file_path, 'r') as file:\n",
        "#             for current_line_number, line in enumerate(file, start=1):\n",
        "#                 if current_line_number == line_number:\n",
        "#                     return line.strip()\n",
        "#         return f\"Line {line_number} not found in the file.\"\n",
        "#     except FileNotFoundError:\n",
        "#         return \"File not found.\"\n",
        "#     except Exception as e:\n",
        "#         return f\"An error occurred: {e}\"\n",
        "\n",
        "# # Example usage\n",
        "# file_path = \"./hf_token.txt\"\n",
        "# line_number = int(input(\"Enter the line number you want to read: \"))\n",
        "# specific_line = read_specific_line(file_path, line_number)\n",
        "# print(f\"Line {line_number}: {specific_line}\")"
      ],
      "metadata": {
        "id": "9LnF6ixxNog7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# login(token=str(specific_line))"
      ],
      "metadata": {
        "id": "otVn7bS2Nq2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=\"your_token\")"
      ],
      "metadata": {
        "id": "nVgzCz02TgrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Training Without Checkpointing"
      ],
      "metadata": {
        "id": "oaZwqH9kB7_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x781R7kYf1i9"
      },
      "outputs": [],
      "source": [
        "# !accelerate launch train_text_to_image_lora.py \\\n",
        "#   --pretrained_model_name_or_path=\"ffaizalnf1800/AingDiffusion-V8-FP16-SD1.5-Blessed2Vae\" \\\n",
        "#   --dataset_name=\"finnstrom3693/anime_character_dataset_512\" \\\n",
        "#   --resolution=512  \\\n",
        "#   --train_batch_size=4 \\\n",
        "#   --gradient_accumulation_steps=1 \\\n",
        "#   --learning_rate=1e-4 \\\n",
        "#   --lr_warmup_steps=5 \\\n",
        "#   --lr_scheduler=\"cosine_with_restarts\" \\\n",
        "#   --num_train_epochs=10 \\\n",
        "#   --output_dir=\"anime-character-lora-mp-fp16\" \\\n",
        "#   --push_to_hub \\\n",
        "#   --mixed_precision=\"fp16\" \\\n",
        "#   --hub_model_id=\"anime-character-lora-mp-fp16\" \\\n",
        "#   --num_validation_images=0 \\\n",
        "#   --adam_weight_decay=1e-2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training With Checkpointing"
      ],
      "metadata": {
        "id": "kyVfh42fCCJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"faizalnf1800/AingDiffusion-V8-FP16-SD1.5-Blessed2Vae\" \\\n",
        "  --dataset_name=\"finnstrom3693/anime_character_dataset_512\" \\\n",
        "  --resolution=512  \\\n",
        "  --train_batch_size=2 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --lr_warmup_steps=5 \\\n",
        "  --lr_scheduler=\"cosine_with_restarts\" \\\n",
        "  --num_train_epochs=10 \\\n",
        "  --output_dir=\"anime-character-lora-mp-fp16\" \\\n",
        "  --push_to_hub \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --hub_model_id=\"anime-character-lora-mp-fp16\" \\\n",
        "  --num_validation_images=0 \\\n",
        "  --adam_weight_decay=1e-2 \\\n",
        "  --checkpointing_steps=250\n"
      ],
      "metadata": {
        "id": "2FFgv8PoCBhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full Precision Training With Xformers"
      ],
      "metadata": {
        "id": "InUnAh9xEn9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !accelerate launch train_text_to_image_lora.py \\\n",
        "#   --pretrained_model_name_or_path=\"faizalnf1800/AingDiffusion-V8-FP16-SD1.5-Blessed2Vae\" \\\n",
        "#   --dataset_name=\"finnstrom3693/anime_character_dataset_512\" \\\n",
        "#   --resolution=512  \\\n",
        "#   --train_batch_size=2 \\\n",
        "#   --gradient_accumulation_steps=1 \\\n",
        "#   --learning_rate=1e-4 \\\n",
        "#   --lr_warmup_steps=5 \\\n",
        "#   --lr_scheduler=\"cosine_with_restarts\" \\\n",
        "#   --num_train_epochs=10 \\\n",
        "#   --output_dir=\"anime-character-lora-mp-fp16\" \\\n",
        "#   --push_to_hub \\\n",
        "#   --mixed_precision=\"no\" \\\n",
        "#   --enable_xformers_memory_efficient_attention \\\n",
        "#   --hub_model_id=\"anime-character-lora-mp-fp16\" \\\n",
        "#   --num_validation_images=0 \\\n",
        "#   --checkpointing_steps=250 \\\n",
        "#   --adam_weight_decay=1e-2"
      ],
      "metadata": {
        "id": "c3PhdX_jEl2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}